names(carc)[13] = "C.US"
# Variance-Inflation Factors
vif(lm(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc))
res     = l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=(1:40)/40)
# generalized cross-validation - simplification of usual leave-one-out CV
gcv.car = gcv(res)
opt.t   = gcv.car[which.min(gcv.car[,"gcv"]),1]
plres   = plot(res)
# split graph.window
dev.new()
layout(matrix(c(1,2), 2, 1),heights=c(0.65,0.35))
# plot LASSO
matplot(plres$bound[,"rel.bound"],plres$mat[,-1],type="l",xlim=c(0,1.1),xlab="relative bound",ylab="coefficients",main="lasso for car data set")
text(cbind(1.03,coef(res[40])[-1]),labels(res),adj=0)
abline(v=opt.t,lty=2)
# plot GCV
plot(gcv.car[,"gcv"]~gcv.car[,1],xlim=c(0,1.1),type="l",ylab="GCV",xlab="relative bound",main="parameter selection")
abline(v=opt.t,lty=2)
# coefficients
summary(l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=opt.t))$coefficients
library(car)
library(lasso2)
library(glmnet)
load('C:/Users/86155/Desktop/MULTIVARIATE STAT INFERENCE/carc.rda')
# convert factors to numeric
carc$R78  = as.numeric(as.character(carc$R78))
carc$R77  = as.numeric(as.character(carc$R77))
carc$C.EU = as.numeric(carc$C=="Europe")
carc$C    = as.numeric(carc$C=="US")
names(carc)[13] = "C.US"
# Variance-Inflation Factors
vif(lm(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc))
res     = l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=(1:40)/40)
# generalized cross-validation - simplification of usual leave-one-out CV
gcv.car = gcv(res)
opt.t   = gcv.car[which.min(gcv.car[,"gcv"]),1]
plres   = plot(res)
# split graph.window
dev.new()
layout(matrix(c(1,2), 2, 1),heights=c(0.65,0.35))
# plot LASSO
matplot(plres$bound[,"rel.bound"],plres$mat[,-1],type="l",xlim=c(0,1.1),xlab="relative bound",ylab="coefficients",main="lasso for car data set")
text(cbind(1.03,coef(res[40])[-1]),labels(res),adj=0)
abline(v=opt.t,lty=2)
# plot GCV
plot(gcv.car[,"gcv"]~gcv.car[,1],xlim=c(0,1.1),type="l",ylab="GCV",xlab="relative bound",main="parameter selection")
abline(v=opt.t,lty=2)
# coefficients
summary(l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=opt.t))$coefficients
??gt_estimation
load("~/GitHub/Spring2019-Proj4-group-12/output/bigram_counts.RData")
a=bigram_counts[,c(1,2)]
context_freq <- lapply(a, table)
freq_table <- table(unlist(context_freq))
load("~/GitHub/Spring2019-Proj4-group-12/output/tesseract_vec.RData")
length(tesseract_vec)
sum(length(tesseract_vec[1:100]))
length(tesseract_vec[1])
nchar(tesseract_vec[1])
tesseract_vec[1]
length(tesseract_vec[[1]])
sum(length(tesseract_vec[[1:100]]))
s=0
for (i in 1:100) {
}
for (i in 1:100) {
s+=length(tesseract_vec[[i]])
}
for (i in 1:100) {
s+=length(tesseract_vec[[i]])}
for (i in 1:100)
s+=length(tesseract_vec[[i]])
for (i in 1:100) {
s=s+length(tesseract_vec[[i]])}
s
s^2
s^2-sum(bigram_counts$freq)
table(bigram_counts$freq)
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/feature.R')
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
set.seed(2018)
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
train_dir <- "C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
# source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
# source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/feature.R')
# source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/feature.R')
# source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/feature.R')
# source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/feature.R')
# source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
#save(dat_train, file="./output/feature_train.RData")
r=table(bigram_counts$freq)
dim(r)
r
names(r)
load("~/GitHub/Spring2019-Proj4-group-12/output/all_text.RData")
a=strsplit(all_text,split=" ")%>%.[[1]]
a=unique(a)
length(a)^2
length(a)^2-sum(bigram_counts$freq)
r["1"]
r[104]
r[114]
names(r[114])
as.integer(names(r[114]))
r_star = c()
for (i in 1:(length(r)-1)) {
r_star = c(r_star,(as.integer(names(r[i]))+1)*r[i+1]/r[i])
}
r_star = c(r_star, r[i+1])
names(r_star) = names(r)
r_star
i=223
r[i]
r[i+1]
r_star = c()
for (i in 1:(length(r)-1)) {
r_star = c(r_star,(as.integer(names(r[i]))+1)*r[i+1]/r[i])
}
r_star = c(r_star, r[length(r)]+1)
names(r_star) = names(r)
r
r_star
r_star = c()
for (i in 1:(length(r)-1)) {
r_star = c(r_star,(as.integer(names(r[i]))+1)*r[i+1]/r[i])
}
r_star = c(r_star, as.integer(names(r[length(r)]))+1)
names(r_star) = names(r)
r_star
i
r["i"]
r[as.character(6458)]
f = c()
for (j in 1:nrow(bigram_counts)) {
f = c(f,r_star[as.character(bigram_counts[j,]$freq)])
}
f[1:10]
bigram_counts = cbind(bigram_counts,f)
save(bigram_counts,file = './output/bigram_counts.RData')
(bigram_counts[which((bigram_counts$l=="NUll") & (bigram_counts$r==1)),]
)
bigram_counts[which((bigram_counts$l=="NUll") & (bigram_counts$r==1)),]$f
bigram_counts[which((bigram_counts$l=="NUll") & (bigram_counts$r==1)),]$f==0
bigram_counts[which((bigram_counts$l=="NUll") & (bigram_counts$r==1)),]$f+1
bigram_counts[which((bigram_counts$l=="NUll") & (bigram_counts$r==1)),]$f==NA
numeric(0)
numeric(0)==0
bigram_counts[which((bigram_counts$l=="NUll") & (bigram_counts$r==1)),]$f==numeric(0)
which((bigram_counts$l=="NUll") & (bigram_counts$r==1))
which((bigram_counts$l=="NUll") & (bigram_counts$r==1))==0
ifelse(which((bigram_counts$l=="NUll") & (bigram_counts$r==1)), 1, 0)
ifelse(which((bigram_counts$l=="NUll") & (bigram_counts$r==1)), 1,2)
ifelse(1, 1,2)
r[1]
library(dplyr)
library(tidyr)
library(stringr)
context_prob = function(l, c, r){
l = cleantext(l) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[length(.)]
r = cleantext(r) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[1]
pc_l = sum(bigram_counts[which(bigram_counts$r==c),]$f)
pc_r = sum(bigram_counts[which(bigram_counts$l==c),]$f)
pl = bigram_counts[which((bigram_counts$l==l) & (bigram_counts$r==c)),]$f %>%
ifelse(length(.),./pc_l, 31504/316887918)
pr = bigram_counts[which((bigram_counts$l==c) & (bigram_counts$r==r)),]$f %>%
ifelse(length(.),./pc_r, 31504/316887918)
return(c(pl,pr))
}
bigram_counts[which((bigram_counts$l==".") & (bigram_counts$r=="the")),]$f
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f/bigram_counts[which((bigram_counts$r=="the")),]$f
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f/sum(bigram_counts[which((bigram_counts$r=="the")),]$f)
context_prob(".","the", "of")
source('~/GitHub/Spring2019-Proj4-group-12/lib/cleantext.R')
context_prob(".","the", "of")
31504/316887918
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(.),./pc_l, 31504/316887918/pc_l)
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(.)>0,./pc_l, 31504/316887918/pc_l)
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(.)>0,., 31504)
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(.)>0,., 31504/316)
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(.)>0,., 31504/316887918)
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(.)<00,., 31504/316887918)
99161/614194897
context_prob = function(l, c, r){
l = cleantext(l) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[length(.)]
r = cleantext(r) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[1]
pc_l = sum(bigram_counts[which(bigram_counts$r==c),]$f)
pc_r = sum(bigram_counts[which(bigram_counts$l==c),]$f)
pl = bigram_counts[which((bigram_counts$l==l) & (bigram_counts$r==c)),]$f %>%
ifelse(length(.)>0,./pc_l, 31504/316887918)
pr = bigram_counts[which((bigram_counts$l==c) & (bigram_counts$r==r)),]$f %>%
ifelse(length(.)>0,./pc_r, 31504/316887918)
return(c(pl,pr))
}
context_prob(".","the","of")
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(.)>0,./pc_l, 31504/316887918)
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(.)>0,./pc_l, 31504/3168879)
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(.)>0,1, 31504/3168879)
?ifelse
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(1)>0,1, 31504/3168879)
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(.)>0,./2, 31504)
bigram_counts[which((bigram_counts$l=="NULL") & (bigram_counts$r=="the")),]$f %>%
ifelse(length(.)>0,./2)
context_prob = function(l, c, r){
l = cleantext(l) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[length(.)]
r = cleantext(r) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[1]
pc_l = sum(bigram_counts[which(bigram_counts$r==c),]$f)
pc_r = sum(bigram_counts[which(bigram_counts$l==c),]$f)
pl = bigram_counts[which((bigram_counts$l==l) & (bigram_counts$r==c)),]$f
pl = ifelse(length(pl)>0, pl/pc_l, 31504/316887918)
pr = bigram_counts[which((bigram_counts$l==c) & (bigram_counts$r==r)),]$f
pr = ifelse(length(pr)>0, pr/pc_r, 31504/316887918)
return(c(pl,pr))
}
context_prob(".","the","of")
t = data.frame(l=bigram_counts$l[1:10], c = bigram_counts$r[1:10], r = bigram_counts$l[1:10])
t
lapply(t, context_prob)
context_prob(t[1,])
t[1,]
a,b = 1,1
c(a,b) = 1,1
context_prob = function(l, c, r){
l = text[1]; c = text[2]; r = text[3]
l = cleantext(l) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[length(.)]
r = cleantext(r) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[1]
pc_l = sum(bigram_counts[which(bigram_counts$r==c),]$f)
pc_r = sum(bigram_counts[which(bigram_counts$l==c),]$f)
pl = bigram_counts[which((bigram_counts$l==l) & (bigram_counts$r==c)),]$f
pl = ifelse(length(pl)>0, pl/pc_l, 31504/316887918)
pr = bigram_counts[which((bigram_counts$l==c) & (bigram_counts$r==r)),]$f
pr = ifelse(length(pr)>0, pr/pc_r, 31504/316887918)
return(c(pl,pr))
}
lapply(t, context_prob)
context_prob = function(text){
l = text[1]; c = text[2]; r = text[3]
l = cleantext(l) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[length(.)]
r = cleantext(r) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[1]
pc_l = sum(bigram_counts[which(bigram_counts$r==c),]$f)
pc_r = sum(bigram_counts[which(bigram_counts$l==c),]$f)
pl = bigram_counts[which((bigram_counts$l==l) & (bigram_counts$r==c)),]$f
pl = ifelse(length(pl)>0, pl/pc_l, 31504/316887918)
pr = bigram_counts[which((bigram_counts$l==c) & (bigram_counts$r==r)),]$f
pr = ifelse(length(pr)>0, pr/pc_r, 31504/316887918)
return(c(pl,pr))
}
lapply(t, context_prob)
sapply(t, context_prob)
apply(t, 1, context_prob)
t
load("~/GitHub/Spring2019-Proj4-group-12/output/cand_prob_wt_cont_gd.RData")
load("C:/Users/86155/Downloads/Fall2018-Project4-sec2-grp11-master/output/corrected.RData")
load("C:/Users/86155/Downloads/Fall2018-Project4-sec2-grp11-master/output/corrected.RData")
corrected_list[[1]]
load("~/GitHub/Spring2019-Proj4-group-12/output/cand_prob_wt_cont_gd.RData")
length(cand_prob_wt_context_df$typo)
length(cand_prob_wt_context_df$correction)
cand_prob_wt_context_df$correction[1]
cand_prob_wt_context_df$correction[2]
cand_prob_wt_context_df$typo[1]
cand_prob_wt_context_df$typo[2]
load("~/GitHub/Spring2019-Proj4-group-12/output/tesseract_vec.RData")
cand_prob_wt_context_df$typo=="xansm"
which(cand_prob_wt_context_df$typo=="xansm")
load("~/GitHub/Spring2019-Proj4-group-12/output/candidates_gd.RData")
load("~/GitHub/Spring2019-Proj4-group-12/output/typos.RData")
length(unique(typos$typo))
length(unique(cand_prob_wt_context_df$typo))
t = typos[1:10,]
t
merge(x=t, y=candidates_gd, by.x = typo, by.y= typo)
merge(x=t, y=candidates_gd, by.x = t$typo, by.y= candidates_gd$typo, all.x = TRUE)
merge(x=t, y=candidates_gd, by=typo, all.x = TRUE)
merge(x=t, y=candidates_gd, by="typo", all.x = TRUE)
tesseract_vec[[1]]
t=typos[1:100]
t=typos[1:100,]
t
c = cand_prob_wt_context_df[1:20,]
merge(x=c,y=t,by="typo",all.y = TRUE)
tesseract_vec[1][7]
tesseract_vec[[1]][7]
load("~/GitHub/Spring2019-Proj4-group-12/output/bigram_counts.RData")
sum(bigram_counts$l=="bay")
sum(bigram_counts$l=="bly")
sum(bigram_counts$l=="buy")
sum(bigram_counts$r=="buy")
sum(bigram_counts$r=="bly")
sum(bigram_counts$r=="bay")
which(bigram_counts$r=="bay")
which(bigram_counts$r=="bly")
which(bigram_counts$l=="bly")
bigram_counts[49748]
bigram_counts[49748,]
bigram_counts[121060,]
merge(x=cand_prob_wt_context_df,y=typos,by="typo",all.x=TRUE)
t = merge(x=cand_prob_wt_context_df,y=typos,by="typo",all.x=TRUE)
sum(is.na(t$posx))
sum(is.na(t$posy))
t[which(is.na(t$posx)),][1:10]
t[is.na(t$posx),][1:10]
t[which(is.na(t$posx)==TRUE),][1:10]
t[which(is.na(t$posx)==TRUE),][1:10,]
unique(t[which(is.na(t$posx)==TRUE),1])
cand_prob_wt_context_df[which(cand_prob_wt_context_df$typo=="action"),]
cand_prob_wt_context_df[which(candidates_gd$typo=="action"),]
candidates_gd[which(candidates_gd$typo=="action"),]
candidates_gd[which(candidates_gd$typo=="environment"),]
candidates_gd[which(candidates_gd$typo=="has"),]
candidates_gd[which(candidates_gd$typo=="party"),]
get_lr = function(pos){
x=pos[1];y=pos[2]
l = ifelse(y!=1, tesseract_vec[[x]][y-1], ".")
r = ifelse(y!=length(tesseract_vec[[x]]), tesseract_vec[[x]][y+1], ".")
return(c(l,r))
}
apply(t[1:10,c(5,6)], 1, get_lr)
context_prob = function(text){
l = text[1]; c = text[2]; r = text[3]
l = cleantext(l) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[length(.)]
r = cleantext(r) %>%
strsplit(., split = " ") %>%
.[[1]] %>%
.[1]
pc_l = sum(bigram_counts[which(bigram_counts$r==c),]$f)
pc_r = sum(bigram_counts[which(bigram_counts$l==c),]$f)
pl = bigram_counts[which((bigram_counts$l==l) & (bigram_counts$r==c)),]$f
pl = ifelse(length(pl)>0, pl/pc_l, 31504/316887918)
pr = bigram_counts[which((bigram_counts$l==c) & (bigram_counts$r==r)),]$f
pr = ifelse(length(pr)>0, pr/pc_r, 31504/316887918)
return(c(pl,pr))
}
t[1,]
context_prob(c("cut","by","the"))
source('~/GitHub/Spring2019-Proj4-group-12/lib/cleantext.R')
context_prob(c("cut","by","the"))
context_prob(c("cut","buy","the"))
context_prob(c("cut","bly","the"))
context_prob(c("cut","bay","the"))
context_prob(c("recently","bay","the"))
context_prob(c("recently","by","the"))
typos[which(typos$typo=="has")]
typos[which(typos$typo=="has"),]
get_lr(NA,NA)
t = merge(x=cand_prob_wt_context_df,y=typos,by="typo",all.x=TRUE) %>%
.[which(is.na(.$posx)==FALSE),]
a = apply(t[,c(5,6)], 1, get_lr)
dim(a)
a[2,1:10]
a[,1:10]
a[[2]][1:10]
a=t(a)
a[1:10,2]
a[1:10,]
t[,5]=a[,1];t[.6]=a[,2]
colnames(t[,c(5,6)]) = c("l","r")
t[,6]=a[,2]
names(t[,5])
colnames(t[,5])
colnames(t[,c(5,6)])
colnames(t[,c(5,6)])=c("l","r")
colnames(t)=c("typo","correction","pc","ptc","l","r")
p = t(apply(t[,c(5,2,6)], 1, context_prob))
p[1:10,]
p[which(p[1,]>0.0001),]
p[which(p[,1]>0.0001),]
p[which((p[,1]>0.0001)and(p[,2]>0.0001)),]
p[which((p[,1]>0.0001)$(p[,2]>0.0001)),]
p[which((p[,1]>0.0001)&(p[,2]>0.0001)),]
t[c(15121,15123)]
t[c(15121,15123),]
typos$typo=tolower(typos$typo) %>% gsub("[[:punct:]]","",.)
t = merge(x=cand_prob_wt_context_df,y=typos,by="typo",all.x=TRUE) %>%
.[which(is.na(.$posx)==FALSE),]
sum(is.na(t$posx))
a = t(apply(t[,c(5,6)], 1, get_lr))
t[,5]=a[,1];t[,6]=a[,2]
colnames(t)=c("typo","correction","pc","ptc","l","r")
p = t(apply(t[,c(5,2,6)], 1, context_prob))
p[which((p[,1]>0.0001)&(p[,2]>0.0001)),]
t[1,]
t1=merge(x=cand_prob_wt_context_df,y=typos,by="typo",all.x=TRUE)
t[1:10,]
t1[1:10,]
tesseract_vec[[55]][3378]
t = cbind(t,p)
t[29632,]
t[29634,]
t[29636,]
t[5506,]
t[19567,]
t = t[,c(1,2,5,6,3,4,7,8)]
colnames(t)=c("typo","correction",,"l","r","pc","ptc","pl|c","pr|c")
colnames(t)=c("typo","correction","l","r","pc","ptc","pl|c","pr|c")
final_prob=t
save(final_prob,file = './output/final_prob.RData')
source('~/GitHub/Spring2019-Proj4-group-12/lib/context_prob.R')
View(final_prob)
source('~/GitHub/Spring2019-Proj4-group-12/lib/context_prob.R')
typos$typo=tolower(typos$typo) %>% gsub("[[:punct:]]","",.)
final_prob = merge(x=cand_prob_wt_context_df,y=typos,by="typo",all.x=TRUE) %>%
.[which(is.na(.$posx)==FALSE),]
a = t(apply(final_prob[,c(5,6)], 1, get_lr))
final_prob[,5]=a[,1];final_prob[,6]=a[,2]
p = t(apply(final_prob[,c(5,2,6)], 1, context_prob))
final_prob = cbind(final_prob,p)
final_prob = final_prob[,c(1,2,5,6,3,4,7,8)]
colnames(final_prob)=c("typo","correction","l","r","pc","ptc","pl|c","pr|c")
save(final_prob,file = './output/final_prob.RData')
View(final_prob)
