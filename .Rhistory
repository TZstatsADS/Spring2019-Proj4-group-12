load("C:/Users/86155/Downloads/xgboost_models.RData")
View(models_final)
# function carries out $K$-fold cross-validation for the linear svm
svm_linear_cv=function(k, cost) {
ncost = length(cost)
validation_error_mat=matrix(NA,k,ncost)
for( j in 1:k){
validation_index=c((j-1)*(length(train)%/%k)+1:(length(train)%/%k)) ## the training data has already been shuffled.
train_index=c(1:length(train))[-validation_index]
svm.linear.mod = svm(text[train_index,],ytrain[train_index],cost=cost,scale = FALSE)
validation_error_mat[j,] =cv_error(fitted_model=svm.linear.mod,newy=ytrain[validation_index],newx= text[validation_index,])
}
return(validation_error_mat)
}
library(e1071)
text5 = read.table("C:/Users/86155/Desktop/train.5.txt",sep=",")
text6 = read.table("C:/Users/86155/Desktop/train.6.txt",sep=",")
text = rbind(text5,text6)
y = c(rep(-1,nrow(text5)),rep(1,nrow(text6)))
n = nrow(text)
train = sample(1:n, n*0.8)
x_train = text[train, ]
y_train = y[train]
x_test = text[-train, ]
y_test = y[-train]
svm_linear_cv(5,10)
n <- nrow(text)
# We fist set aside a test set, which contains 30% data points.
train = sample(1:n, n*0.8)
test= c(1:n)[-train]
ytest = y[test]
xtrain=text[train,]
ytrain=y[train]
svm_linear_cv(10)
svm_linear_cv(5,10)
# function is to calculate the average loss of a model on a data set
cv_error=function(fitted_model,newy,newx){
pred <- predict(fitted_model, newx)
error=mean((pred-newy)^2)
return(error)
}
svm_linear_cv(5,10)
model1 = svm(x_train,y_train,kernel = "linear",cost=10, scale = FALSE)
model1 = svm(x_train,y_train,cost=10, scale = FALSE)
pred(object=model1, newdata = x_train[1:10])
predict(object=model1, newdata = x_train[1:10,])
svm_rbf_cv=function(c, g, k=5) {
n = nrow(x_train)
index = sample(1:n, n)
mis_rate = rep(NA, k)
for(j in 1:k){
i = ((j-1)*(n%/%k)+1):(j*(n%/%k))
test_index = index[i]
train_index = index[-i]
model1 = svm(x_train[train_index,],y_train[train_index], cost=c, scale = FALSE)
y_pred = predict(object = model1, newdata = x_train[test_index,])
y_pred = ifelse(y_pred<0, -1, 1)
mis_rate[j] = sum(y_pred != y_train[test_index])/length(test_index)
}
return(mean(mis_rate))
}
svm_linear_cv=function(c, k=5) {
n = nrow(x_train)
index = sample(1:n, n)
mis_rate = rep(NA, k)
for( j in 1:k){
i = ((j-1)*(n%/%k)+1):(j*(n%/%k))
test_index = index[i]
train_index = index[-i]
model1 = svm(x_train[train_index,],y_train[train_index],cost=c, scale = FALSE)
y_pred = predict(object = model1, newdata = x_train[test_index,])
y_pred = ifelse(y_pred<0, -1, 1)
mis_rate[j] = sum(y_pred != y_train[test_index])/length(test_index)
}
return(mean(mis_rate))
}
svm_linear_cv(10)
cost = c(0.1, 0.2, 0.5, 1, 2, 5, 10)
train_misrate = sapply(cost, svm_linear_cv)
plot(cost, train_misrate, ylab = "misclassification rate", type = "l")
svm_rbf_cv=function(c, g, k=5) {
n = nrow(x_train)
index = sample(1:n, n)
mis_rate = rep(NA, k)
for(j in 1:k){
i = ((j-1)*(n%/%k)+1):(j*(n%/%k))
test_index = index[i]
train_index = index[-i]
model1 = svm(x_train[train_index,],y_train[train_index], kernel = "rbf", cost=c, gamma=g, scale = FALSE)
y_pred = predict(object = model1, newdata = x_train[test_index,])
y_pred = ifelse(y_pred<0, -1, 1)
mis_rate[j] = sum(y_pred != y_train[test_index])/length(test_index)
}
return(mean(mis_rate))
}
svm_rbf_cv(0.1,0.1)
svm_rbf_cv=function(c, g, k=5) {
n = nrow(x_train)
index = sample(1:n, n)
mis_rate = rep(NA, k)
for(j in 1:k){
i = ((j-1)*(n%/%k)+1):(j*(n%/%k))
test_index = index[i]
train_index = index[-i]
model1 = svm(x_train[train_index,],y_train[train_index], kernel = "radial", cost=c, gamma=g, scale = FALSE)
y_pred = predict(object = model1, newdata = x_train[test_index,])
y_pred = ifelse(y_pred<0, -1, 1)
mis_rate[j] = sum(y_pred != y_train[test_index])/length(test_index)
}
return(mean(mis_rate))
}
svm_rbf_cv(0.1,0.1)
cost = c(0.1, 1, 10)
gamma = seq(0.1, 0.5, length = 5)
para = cbind(rep(cost, 5), rep(gamma, each = 3))
para
cost = c(0.1, 1, 10)
gamma = seq(0.1, 0.5, length = 5)
para = cbind(rep(cost, 5), rep(gamma, each = 3))
rate_rbf = apply(para, 1, svm_rbf_cv)
apply(para,1,sum)
rate_rbf = apply(para, 1, svm_rbf_cv)
svm_rbf_cv=function(para, k=5) {
c = para[1]; g = para[2]
n = nrow(x_train)
index = sample(1:n, n)
mis_rate = rep(NA, k)
for(j in 1:k){
i = ((j-1)*(n%/%k)+1):(j*(n%/%k))
test_index = index[i]
train_index = index[-i]
model1 = svm(x_train[train_index,],y_train[train_index], kernel = "radial", cost=c, gamma=g, scale = FALSE)
y_pred = predict(object = model1, newdata = x_train[test_index,])
y_pred = ifelse(y_pred<0, -1, 1)
mis_rate[j] = sum(y_pred != y_train[test_index])/length(test_index)
}
return(mean(mis_rate))
}
cost = c(0.1, 1, 10)
gamma = seq(0.1, 0.5, length = 5)
para = cbind(rep(cost, 5), rep(gamma, each = 3))
rate_rbf = apply(para, 1, svm_rbf_cv)
rate_rbf
?heatmap
heatmap(para)
heatmap(cbind(para, rate_rbf))
heatmap(rate_rbf)
heatmap(matrix(rate_rbf, ncol = 1))
heatmap(matrix(1:4,2))
para
rate_rbf = matrix(rate_rbf, nrow = 3)
colnames(rate_rbf) = cost
colnames(rate_rbf) = c(0.1,1,10)
colnames(rate_rbf) = as.character(c(0.1,1,10))
rate_rbf = matrix(rate_rbf, nrow = 3)
colnames(rate_rbf) = gamma
rownames(rate_rbf) = cost
heatmap(rate_rbf)
para
rate_rbf
model1 = svm(x_train,y_train,cost=10, scale = FALSE)
y_pred = predict(object = model1, newdata = x_test)
y_pred = ifelse(y_pred<0, -1, 1)
linear_misrate = sum(y_pred != y_test)/length(y_test)
model2 = svm(x_train,y_train,cost=10, gamma = 0.1, kernel = "radial",scale = FALSE)
y_pred = predict(object = model2, newdata = x_test)
y_pred = ifelse(y_pred<0, -1, 1)
rbf_misrate = sum(y_pred != y_test)/length(y_test)
c(linear_misrate, rbf_misrate)
model1 = svm(x_train,y_train,cost=100, scale = FALSE)
y_pred = predict(object = model1, newdata = x_test)
y_pred = ifelse(y_pred<0, -1, 1)
sum(y_pred != y_test)/length(y_test)
sum(y_pred != y_test)/length(y_test)
model1 = svm(x_train,y_train,cost=1, scale = FALSE)
y_pred = predict(object = model1, newdata = x_test)
y_pred = ifelse(y_pred<0, -1, 1)
sum(y_pred != y_test)/length(y_test)
load("~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/output/GBM/fit_train.RData")
set.seed(2018)
setwd("~/Desktop/Fall18/GR5243_ADS/Assignment3/Fall2018-Proj3-Sec2-grp5/doc")
set.seed(2018)
setwd("C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
source('C:/Users/86155/Desktop/Fall2018-Proj3-Sec2-grp5-master/lib/GBM_Baseline/superResolution.R')
source('C:/Users/86155/Desktop/Fall2018-Proj3-Sec2-grp5-master/lib/GBM_Baseline/train.R')
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/GBM/test.R')
test_dir <- "C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4//data/test_set/" # This will be modified for different data sets.
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")
tm_test=NA
if(run.test){
load(file="C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/output/GBM/fit_train.RData")
tm_test <- system.time(superResolution(test_LR_dir, test_HR_dir, fit_train))
}
run.test = 1
tm_test=NA
if(run.test){
load(file="C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/output/GBM/fit_train.RData")
tm_test <- system.time(superResolution(test_LR_dir, test_HR_dir, fit_train))
}
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/XGboost/superResolution_xgboost.R')
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/XGboost/superResolution_xgboost.R')
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/XGboost/test_xgboost.R')
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/XGboost/train_xgboost.R')
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/XGboost/superResolution_xgboost.R')
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/XGboost/superResolution_xgboost.R')
source('C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/XGboost/superResolution_xgboost.R')
#test_dir <- "../data/test_set/XGB_3_3/" # This will be modified for different data sets.
#test_LR_dir <- paste(test_dir, "LR/", sep="")
#test_HR_dir <- paste(test_dir, "HR/", sep="")
test_LR_dir <- "C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/data/test_set/LR/"
test_HR_dir <- "C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/data/test_set/HR/"
tm_test=NA
run.test <- T
if(run.test){
load(file="C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/output/fit_train_xgboost.RData")
tm_test <- system.time(superResolution_xgboost(test_LR_dir, test_HR_dir, fit_train_xgboost_3_3))
}
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/XGboost/superResolution_xgboost.R')
if(run.test){
load(file="C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/output/fit_train_xgboost.RData")
tm_test <- system.time(superResolution_xgboost(test_LR_dir, test_HR_dir, fit_train_xgboost_3_3))
}
1000:998
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/GBM/train.R')
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/GBM/test.R')
source('~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/lib/GBM/superResolution.R')
load("~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/output/GBM/fit_train.RData")
tm_test <- system.time(superResolution(test_LR_dir, test_HR_dir, fit_train))
test_LR_dir = "C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/data/LR/"
test_HR_dir = "C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/data/HR/"
tm_test <- system.time(superResolution(test_LR_dir, test_HR_dir, fit_train))
superResolution(test_LR_dir, test_HR_dir, fit_train)
imgLR <- readImage(paste0(test_LR_dir,  "img", "_", sprintf("%04d", 1000), ".jpg"))
test_LR_dir = "C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/data/test_set/LR/"
test_HR_dir = "C:/Users/86155/Documents/GitHub/Spring2019-Proj3-spring2019-proj3-grp4/data/test_set/HR/"
superResolution(test_LR_dir, test_HR_dir, fit_train)
load("~/GitHub/Spring2019-Proj4-group-12/output/ground_truth_frequency.RData")
View(ground_truth_freq)
install.packages("ngram")
load("~/GitHub/Spring2019-Proj4-group-12/output/detection_result.RData")
View(detection_result)
length(detection_result[[1]])
load("~/GitHub/Spring2019-Proj4-group-12/output/tesseract_vec.RData")
View(list)
?ngram
library(ngram)
?ngram
str <- "A B A C A B B"
ngram(str, n=2)
print(ngram(str), output="full")
a=ngram(list[[1]])
length(list[[1]])
list[[1]][1]
list[[1]][1:2]
str = "A B C" "v d"
s=list[[1]][1:10]
s
ngram(s)
ngram(paste(s,sep=" "))
paste(s,sep=" ")
str
s
paste
?paste
mode(s)
s[1]
paste(s[1],s[2],sep=" ")
paste(s[1:10],sep=" ")
is.list(s)
paste(s[1:10],sep=" ", collapse = " ")
paste(s[1:10], collapse = " ")
ngram(paste(s,collapse =" "))
a=ngram(paste(s,collapse =" "))
names(a)
mode(a)
a
a[1]
get.phrasetable(a)
get.phrasetable(ngram(str))
get.phrasetable(ngram(str))[1]
t=get.phrasetable(ngram(str))
t$ngrams
mode(t)
t[1,]
t['A B ']
t$ngrams=='A B '
data.frame(t)
install.packages("dplyr")
bigrams = data.frame(t)
bigram_counts = bigrams %>%
separate(ngrams, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
bg = unlist(strsplit(bigrams$ngrams, " "))
bigram_counts = matrix(bg, ncol = 2, nrow = length(bg)/2, byrow = TRUE)
bigram_counts = data.frame(bigram_counts, bigrams$freq)
colnames(bigram_counts) = c("word1", "word2", "freq")
bigram_counts
load("~/GitHub/Spring2019-Proj4-group-12/output/tesseract_vec.RData")
library(ngram)
library(dlypt)
library(ngram)
library(dplyr)
library(tidyr)
library(stringr)
setwd("C:/Users/86155/Documents/GitHub/Spring2019-Proj4-group-12")
load("~/GitHub/Spring2019-Proj4-group-12/output/ground_truth_all_lines.RData")
#paste(str_trim(gd_lines), sep = " ", collapse = " ")
## deal with punctuation
all_text = gd_all_lines %>%
gsub("\\(","",.) %>%
gsub("\\)","",.) %>%
gsub("\\\"","",.) %>%
gsub("\\'","",.) %>%
gsub("\\$","",.) %>%
gsub("\\..."," ",.) %>%
tolower(.) %>%
paste(str_trim(.), sep = " ", collapse = " ") %>%
gsub("[:punct:]"," 0 ",.)
save(all_text, file='/all_text')
save(all_text, file='/all_text.txt')
save(all_text, file='./all_text.RData')
a=gd_all_lines[1]
gsub("[:punct:]"," 0 ",a)
b="afe. ew 2"
gsub("[:punct:]"," 0 ",b)
gsub("[:punct:]*"," 0 ",b)
gsub("[:punct:]$"," 0 ",b)
gsub("$[:punct:]"," 0 ",b)
gsub("*[:punct:]"," 0 ",b)
gsub("[:punct:]*"," 0 ",b)
b="afe. ew 2 ."
gsub("[:punct:]*"," 0 ",b)
gsub("[:punct:]"," 0 ",b)
gsub("[[:punct:]]"," 0 ",b)
all_text = gd_all_lines %>%
gsub("\\(","",.) %>%
gsub("\\)","",.) %>%
gsub("\\\"","",.) %>%
gsub("\\'","",.) %>%
gsub("\\$","",.) %>%
gsub("\\..."," ",.) %>%
tolower(.) %>%
paste(str_trim(.), sep = " ", collapse = " ") %>%
gsub("[[:punct:]]"," 0 ",.)
ng <- ngram (all_text, n =  2)
bigrams = data.frame(get.phrasetable(ng))
bigram_counts = bigrams %>%
separate(ngrams, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
bigram_counts = bigrams %>%
separate(ngrams, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = FALSE)
bigram_counts = bigrams %>%
separate(ngrams, c("word1", "word2"), sep = " ")
bigram_counts = bigrams %>%
separate(ngrams, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
bigram_counts[155296,]
bigram_counts[,which(bigram_counts$n>100)]
bigram_counts = bigrams %>%
separate(ngrams, c("word1", "word2"), sep = " ")
bigram_counts[1,]
bigram_counts[which(bigram_counts$word1=="of" and bigram_counts$word2=="the"),]
bigram_counts[which(bigram_counts$word1=="of"),]
bigram_counts[which(bigram_counts$word1=="of" &  and bigram_counts$word2=="the"),]
bigram_counts[which((bigram_counts$word1=="of") & (bigram_counts$word2=="the")),]
bigram_counts[1:10,c("word1","freq")]
bigram_counts[which(bigram_counts$word1=="1" &  and bigram_counts$word2=="1"),]$freq
bigram_counts[which((bigram_counts$word1=="of") & (bigram_counts$word2=="1")),]$freq
bigram_counts[which((bigram_counts$word1=="1") & (bigram_counts$word2=="1")),]$freq
bigram_counts[which((bigram_counts$word1=="1") & (bigram_counts$word2=="199999")),]$freq
bigram_counts = bigrams %>%
separate(ngrams, c("l", "r"), sep = " ") %>%
.[,c("l","r",freq)]
save(bigram_counts,file = '../output/bigram_counts.RData')
save(bigram_counts,file = '../output/bigram_counts.RData')
save(bigram_counts,file = './output/bigram_counts.RData')
load("~/GitHub/Spring2019-Proj4-group-12/output/bigram_counts.RData")
source('~/GitHub/Spring2019-Proj4-group-12/lib/context_prob.R')
load("~/GitHub/Spring2019-Proj4-group-12/output/ground_truth_frequency.RData")
ground_truth_freq[1,]
load("~/GitHub/Spring2019-Proj4-group-12/output/tesseract_vec.RData")
