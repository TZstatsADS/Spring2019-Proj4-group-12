header=F)
label_train <- as.numeric(unlist(label_train) == "9")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir,
"train",
data_name="zipcode",
export=TRUE))
}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir,
"train",
data_name="zip",
export=TRUE))
}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir,
"train",
data_name="zip",
export=TRUE))
}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir,
"train",
data_name="zip",
export=TRUE))
}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir,
"train",
data_name="zip",
export=TRUE))
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(img_test_dir,
"test",
data_name="zip",
export=TRUE))
#save(dat_train, file="./output/feature_train.RData")
#save(dat_test, file="./output/feature_test.RData")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir,
"train",
data_name="zip",
export=TRUE))
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(img_test_dir,
"test",
data_name="zip",
export=TRUE))
}
#save(dat_train, file="./output/feature_train.RData")
#save(dat_test, file="./output/feature_test.RData")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(depth_values), 2))
for(k in 1:length(depth_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(depth_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
experiment_dir <- "../data/zipcode/" # This will be modified for different data sets.
img_train_dir <- paste(experiment_dir, "train/", sep="")
img_test_dir <- paste(experiment_dir, "test/", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels = paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep=""),
header=F)
label_train <- as.numeric(unlist(label_train) == "9")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir,
"train",
data_name="zip",
export=TRUE))
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(img_test_dir,
"test",
data_name="zip",
export=TRUE))
}
#save(dat_train, file="./output/feature_train.RData")
#save(dat_test, file="./output/feature_test.RData")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
if(run.cv){
load("../output/err_cv.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.15))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2],depth_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
#dev.off()
}
if(run.cv){
load("../output/err_cv.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.15))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
#dev.off()
}
if(run.cv){
load("../output/err_cv.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.25))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
#dev.off()
}
model_best=model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[,1])]
}
par_best <- list(par=model_best)
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
View(err_cv)
which.min(err_cv[,1])
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
fit_train <- train(dat_train, label_train, par_best)
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par=par_best))
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par=par_best))
par_best$par
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
source('~/Dropbox/Tian_Teaching/G5243-ADS/0-Projects-startercodes/3-Spring2017/Project3_PoodleKFC/lib/train.R')
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
source('~/Dropbox/Tian_Teaching/G5243-ADS/0-Projects-startercodes/3-Spring2017/Project3_PoodleKFC/lib/train.R')
model_best=model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[,1])]
}
par_best <- list(depth=model_best)
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
save(fit_train, file="../output/fit_train.RData")
tm_test=NA
if(run.test){
load(file=paste0("../output/feature_", "zip", "_", "test", ".RData"))
load(file="../output/fit_train.RData")
tm_test <- system.time(pred_test <- test(fit_train, dat_test))
save(pred_test, file="../output/pred_test.RData")
}
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for making prediction=", tm_test[1], "s \n")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
require("pacman")
install.packages("pacman")
if (!require("pacman")) {
## Make sure your current packages are up to date
update.packages()
## devtools is required
library(devtools)
install_github("trinker/pacman")
}
if (!require("pacman")) {
## Make sure your current packages are up to date
update.packages()
## devtools is required
library(devtools)
install_github("trinker/pacman")
}
install.packages(c("acs", "backports", "bayesplot", "BH", "bit", "bit64", "blogdown", "bookdown", "boot", "broom", "cairoDevice", "car", "caTools", "checkmate", "choroplethr", "chron", "cli", "cluster", "coin", "colourpicker", "countrycode", "curl", "data.table", "dendextend", "devtools", "digest", "doParallel", "dplyr", "DT", "dtplyr", "dygraphs", "ellipse", "evaluate", "factoextra", "FactoMineR", "fansi", "fftwtools", "flexmix", "foreach", "foreign", "formatR", "Formula", "fpc", "gbm", "gdata", "gender", "geosphere", "ggplot2", "ggpubr", "ggrepel", "ggsci", "git2r", "gridExtra", "gtools", "highr", "Hmisc", "htmlTable", "htmlwidgets", "httpuv", "hunspell", "igraph", "inline", "irlba", "iterators", "janeaustenr", "kernlab", "knitr", "lattice", "lazyeval", "lme4", "lmtest", "loo", "mapproj", "maps", "maptools", "markdown", "MASS", "Matrix", "matrixStats", "mclust", "memoise", "mgcv", "mime", "miniUI", "modeltools", "multcomp", "munsell", "mvtnorm", "nloptr", "NLP", "NMF", "OAIHarvester", "openNLPdata", "openssl", "packrat", "pbkrtest", "pkgmaker", "PKI", "plotrix", "ps", "psych", "qdap", "qdapDictionaries", "qdapRegex", "qdapTools", "quantreg", "R6", "randomForest", "RANN", "raster", "Rcpp", "RcppEigen", "RCurl", "registry", "remotes", "reprex", "reshape2", "rgdal", "rgeos", "RgoogleMaps", "rJava", "rjson", "rlang", "rmarkdown", "rngtools", "robustbase", "rpart", "rpart.plot", "rprojroot", "rsconnect", "rscopus", "rstantools", "rstudioapi", "sandwich", "scales", "scatterplot3d", "selectr", "servr", "shiny", "shinyjs", "shinystan", "sm", "sourcetools", "sp", "SparseM", "statmod", "stringdist", "stringi", "stringr", "survival", "syuzhet", "testthat", "TH.data", "threejs", "tidyr", "tidyselect", "tidytext", "tm", "tokenizers", "topicmodels", "trimcluster", "viridis", "WDI", "withr", "wordcloud", "xlsx", "XML", "xml2", "xtable", "xts", "yaml", "zoo"))
if (!require("pacman")) {
## devtools is required
library(devtools)
install_github("trinker/pacman")
}y
install.packages("pacman")
library(packman)
if (!require("pacman")) {
## devtools is required
library(devtools)
install_github("trinker/pacman")
}
if (!require("devtools")) install.packages("devtools")
if (!require("pacman")) {
## devtools is required
library(devtools)
install_github("trinker/pacman")
}
install.packages("devtools")
install.packages("devtools")
install.packages("yaml")
install.packages(c("bit", "cairoDevice", "caTools", "chron", "curl", "data.table", "digest", "dplyr", "fansi", "foreign", "gbm", "ggplot2", "ggrepel", "git2r", "gtools", "igraph", "irlba", "kernlab", "lattice", "lme4", "lmtest", "mapproj", "maps", "maptools", "MASS", "Matrix", "matrixStats", "mclust", "mgcv", "mime", "mvtnorm", "nloptr", "NMF", "openssl", "ps", "quantreg", "randomForest", "RANN", "raster", "Rcpp", "RcppEigen", "RCurl", "rgdal", "rgeos", "rJava", "rjson", "rlang", "robustbase", "rstan", "rstanarm", "scales", "sentimentr", "slam", "sm", "sourcetools", "sp", "StanHeaders", "stringdist", "stringi", "stringr", "survival", "testthat", "tidyr", "tidyselect", "tm", "tokenizers", "wordcloud", "XML", "xml2", "xts", "zoo"))
if (!require("devtools")) install.packages("devtools")
if (!require("pacman")) {
## devtools is required
library(devtools)
install_github("trinker/pacman")
}
install.packages("devtools")
library(devtools)
install.packages("base64enc")
install.packages("devtools")
install.packages("processx")
install.packages("devtools")
install.packages("backports")
install.packages("devtools")
install.packages("glue")
install.packages("devtools")
library(devtools)
if (!require("devtools")) install.packages("devtools")
if (!require("pacman")) {
## devtools is required
library(devtools)
install_github("trinker/pacman")
}
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
source('../lib/ifCleanToken.R')
file_name_vec <- list.files("../data/ground_truth") #97 files in total
### only process one of the files in the folder as an example, in your project, you need to use all the files
current_file_name <- sub(".txt","",file_name_vec[3])
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
load("~/GitHub/Spring2019-Proj4-group-12/output/gd_all.RData")
load("~/GitHub/Spring2019-Proj4-group-12/output/tesseract_vec.RData")
load("~/GitHub/Spring2019-Proj4-group-12/output/tesseract_vec_correct.RData")
ground_truth_vec <- strsplit(gd_all," ")[[1]]%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)
library(dplyr)
ground_truth_vec <- strsplit(gd_all," ")[[1]]%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)
tesseract_vec <- unlist(tesseract_vec)%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)
if (!require("devtools")) install.packages("devtools")
if (!require("pacman")) {
## devtools is required
library(devtools)
install_github("trinker/pacman")
}
# library(lexicon)
library(dplyr)
library(plyr)
library(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
tesseract_delete_error_vec <- str_split(tesseract_vec_new," ")[[1]]%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)
old_intersect_vec <- vecsets::vintersect(ground_truth_vec,tesseract_vec)
new_intersect_vec <- vecsets::vintersect(ground_truth_vec,tesseract_delete_error_vec)
GT_character_vec <- unlist(strsplit(ground_truth_vec,""))
T_character_vec <- unlist(strsplit(tesseract_vec,""))
T_deleted_character_vec <- unlist(strsplit(tesseract_delete_error_vec,""))
## Table
OCR_performance_table <- data.frame("Tesseract" = rep(NA,4),
"Tesseract_with_postprocessing" = rep(NA,4))
old_intersect_character <- vecsets::vintersect(GT_character_vec,T_character_vec)
new_intersect_character <- vecsets::vintersect(GT_character_vec,T_deleted_character_vec)
row.names(OCR_performance_table) <- c("word_wise_recall","word_wise_precision",          "character_wise_recall","character_wise_precision")
OCR_performance_table["word_wise_recall","Tesseract"] <- length(old_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract"] <- length(old_intersect_vec)/length(T_character_vec)
OCR_performance_table["word_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(T_deleted_character_vec)
OCR_performance_table["character_wise_recall","Tesseract"] <- length(old_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract"] <- length(old_intersect_character)/length(tesseract_vec)
OCR_performance_table["character_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(tesseract_delete_error_vec)
kable(OCR_performance_table, caption="Summary of OCR performance")
a=c("","","a")
a[a!=""]
a=c("","","a","b","")
a
a[a!=""]
ground_truth_vec <- strsplit(gd_all," ")[[1]]%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)%>%
.[.!=""]
tesseract_vec <- unlist(tesseract_vec)%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)%>%
.[.!=""]
tesseract_delete_error_vec <- str_split(tesseract_vec_new," ")[[1]]%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)%>%
.[.!=""]
old_intersect_vec <- vecsets::vintersect(ground_truth_vec,tesseract_vec)
new_intersect_vec <- vecsets::vintersect(ground_truth_vec,tesseract_delete_error_vec)
GT_character_vec <- unlist(strsplit(ground_truth_vec,""))
T_character_vec <- unlist(strsplit(tesseract_vec,""))
T_deleted_character_vec <- unlist(strsplit(tesseract_delete_error_vec,""))
old_intersect_character <- vecsets::vintersect(GT_character_vec,T_character_vec)
new_intersect_character <- vecsets::vintersect(GT_character_vec,T_deleted_character_vec)
OCR_performance_table["word_wise_recall","Tesseract"] <- length(old_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract"] <- length(old_intersect_vec)/length(T_character_vec)
OCR_performance_table["word_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(T_deleted_character_vec)
OCR_performance_table["character_wise_recall","Tesseract"] <- length(old_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract"] <- length(old_intersect_character)/length(tesseract_vec)
OCR_performance_table["character_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(tesseract_delete_error_vec)
kable(OCR_performance_table, caption="Summary of OCR performance")
length(old_intersect_vec)/length(tesseract_vec)
length(new_intersect_vec)/length(tesseract_delete_error_vec)
OCR_performance_table["word_wise_recall","Tesseract"] <- length(old_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract"] <- length(old_intersect_vec)/length(tesseract_vec)
OCR_performance_table["word_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(tesseract_delete_error_vec)
OCR_performance_table["character_wise_recall","Tesseract"] <- length(old_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract"] <- length(old_intersect_character)/length(T_character_vec)
OCR_performance_table["character_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(T_deleted_character_vec)
kable(OCR_performance_table, caption="Summary of OCR performance")
a="be.2"
gsub('[[:punct:] ]+','',a)
a="be."
gsub('[[:punct:] ]+','',a)
gsub('[[:punct:] ]+','',a)
a="."
gsub('[[:punct:] ]+','',a)
tesseract_delete_error_vec <- str_split(tesseract_vec_new," ")[[1]]
ground_truth_vec <- strsplit(gd_all," ")
tesseract_delete_error_vec <- str_split(tesseract_vec_new," ")
ground_truth_vec <- strsplit(gd_all," ")
ground_truth_vec <- strsplit(gd_all," ")[[1]]
load("~/GitHub/Spring2019-Proj4-group-12/output/tesseract_vec.RData")
tesseract_vec <- unlist(tesseract_vec)
tesseract_vec <- unlist(tesseract_vec)%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)%>%
.[.!=""]
tesseract_delete_error_vec <- unlist(tesseract_vec_new," ")%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)%>%
.[.!=""]
new_intersect_vec <- vecsets::vintersect(ground_truth_vec,tesseract_delete_error_vec)
new_intersect_character <- vecsets::vintersect(GT_character_vec,T_deleted_character_vec)
OCR_performance_table["word_wise_recall","Tesseract"] <- length(old_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract"] <- length(old_intersect_vec)/length(tesseract_vec)
OCR_performance_table["word_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(tesseract_delete_error_vec)
OCR_performance_table["character_wise_recall","Tesseract"] <- length(old_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract"] <- length(old_intersect_character)/length(T_character_vec)
OCR_performance_table["character_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(T_deleted_character_vec)
kable(OCR_performance_table, caption="Summary of OCR performance")
GT_character_vec <- unlist(strsplit(ground_truth_vec,""))
T_character_vec <- unlist(strsplit(tesseract_vec,""))
T_deleted_character_vec <- unlist(strsplit(tesseract_delete_error_vec,""))
new_intersect_character <- vecsets::vintersect(GT_character_vec,T_deleted_character_vec)
OCR_performance_table["word_wise_recall","Tesseract"] <- length(old_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract"] <- length(old_intersect_vec)/length(tesseract_vec)
OCR_performance_table["word_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(tesseract_delete_error_vec)
OCR_performance_table["character_wise_recall","Tesseract"] <- length(old_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract"] <- length(old_intersect_character)/length(T_character_vec)
OCR_performance_table["character_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(T_deleted_character_vec)
kable(OCR_performance_table, caption="Summary of OCR performance")
load('../output/gd_all.RData')
load('../output/tesseract_vec.RData')
load('../output/tesseract_vec_correction.RData')
load("~/GitHub/Spring2019-Proj4-group-12/output/gd_all.RData")
load("~/GitHub/Spring2019-Proj4-group-12/output/tesseract_vec.RData")
load("~/GitHub/Spring2019-Proj4-group-12/output/tesseract_vec_correct.RData")
ground_truth_vec <- strsplit(gd_all," ")[[1]]%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)%>%
.[.!=""]
tesseract_vec <- unlist(tesseract_vec)%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)%>%
.[.!=""]
tesseract_delete_error_vec <- unlist(tesseract_vec_new," ")%>%
sapply(.,tolower)%>%
as.vector()%>%
gsub('[[:punct:] ]+','',.)%>%
.[.!=""]
## word level
old_intersect_vec <- vecsets::vintersect(ground_truth_vec,tesseract_vec)
new_intersect_vec <- vecsets::vintersect(ground_truth_vec,tesseract_delete_error_vec)
## character level
GT_character_vec <- unlist(strsplit(ground_truth_vec,""))
T_character_vec <- unlist(strsplit(tesseract_vec,""))
T_deleted_character_vec <- unlist(strsplit(tesseract_delete_error_vec,""))
old_intersect_character <- vecsets::vintersect(GT_character_vec,T_character_vec)
new_intersect_character <- vecsets::vintersect(GT_character_vec,T_deleted_character_vec)
## Table
OCR_performance_table <- data.frame("Tesseract" = rep(NA,4),
"Tesseract_with_postprocessing" = rep(NA,4))
row.names(OCR_performance_table) <- c("word_wise_recall","word_wise_precision",          "character_wise_recall","character_wise_precision")
OCR_performance_table["word_wise_recall","Tesseract"] <- length(old_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract"] <- length(old_intersect_vec)/length(tesseract_vec)
OCR_performance_table["word_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(ground_truth_vec)
OCR_performance_table["word_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_vec)/length(tesseract_delete_error_vec)
OCR_performance_table["character_wise_recall","Tesseract"] <- length(old_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract"] <- length(old_intersect_character)/length(T_character_vec)
OCR_performance_table["character_wise_recall","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(GT_character_vec)
OCR_performance_table["character_wise_precision","Tesseract_with_postprocessing"] <- length(new_intersect_character)/length(T_deleted_character_vec)
kable(OCR_performance_table, caption="Summary of OCR performance")
load("~/GitHub/Spring2019-Proj4-group-12/output/cand_prob_wt_cont_gd.RData")
load("~/GitHub/Spring2019-Proj4-group-12/output/all_text.RData")
